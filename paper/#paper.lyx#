#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass ulb_thesis
\options draftfoot
\use_default_options false
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\lang english
Engineering a Runtime System for AQL
\end_layout

\begin_layout Author
your name
\end_layout

\begin_layout Degree
Docteur en XXX
\begin_inset Newline newline
\end_inset

(Département XXX, Faculté XXX)
\end_layout

\begin_layout Dedication
To my parents.
\end_layout

\begin_layout Acknowledgments
Thank you, my advisor!
\end_layout

\begin_layout Standard
\begin_inset VSpace 4cm*
\end_inset


\end_layout

\begin_layout Standard

\emph on
\begin_inset Quotes eld
\end_inset

A great citation here
\emph default

\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
\align right
X
\end_layout

\begin_layout Abstract
abstract of the thesis
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList table

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
mainmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "intro.lyx"

\end_inset


\end_layout

\begin_layout Chapter
Information Extraction
\end_layout

\begin_layout Section
Definition
\end_layout

\begin_layout Standard
Information Extraction (IE) is the discipline that addresses the task of
 extracting structured information from unstructured sources automatically.
 The most explored aspect of IE is the extraction of 
\emph on
named entities.

\emph default
 Another main topic, that has become object of research only in recent years,
 is the extraction of 
\emph on
relationships
\emph default
 between entities.
 IE is a field with contributions from many different communities: Machine
 Learning, Information Retrieval, Database, Web, Document Analysis.
 The interest in towards it is motivated by the evergrowing amount of data
 that is generated by our society, that is at a point in which manual analysis
 is infeasible.
 Thus IE promises to bring value to many application domains, most notably
 the enterprise world and the Web.
 There are two main approaches to IE: 
\emph on
rule-based 
\emph default
and 
\emph on
statistical
\emph default
.
 
\end_layout

\begin_layout Section
Example Applications
\end_layout

\begin_layout Paragraph
News Tracking
\end_layout

\begin_layout Standard
The activity of tracking events in news articles.
 It can result in a lot of useful services, like automatic creation of multimedi
a news, linking articles to information pages on the entities found, etc.
\end_layout

\begin_layout Paragraph
Data Cleaning
\end_layout

\begin_layout Standard
Extracting structured forms from flat data strings (containing, e.g., addresses).
 It allows more effective decuplication of information, among the other
 things.
\end_layout

\begin_layout Paragraph
Citation Databases
\end_layout

\begin_layout Standard
Articles, conferences sites, individual research sites and similar are explored
 to obain formatted citations of publications, later stored in publicly
 accessible databases.
 They are capable to forward references and may provide aggregate statistics
 and scoring information.
 See for instance Google Scholar (
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://scholar.google.it/
\end_layout

\end_inset

).
\end_layout

\begin_layout Paragraph
Relationship Web Search
\end_layout

\begin_layout Standard
Relationship extraction would be a very useful feature to integrate into
 web search engines, as the keyword search that they offer at present time
 is only good for entity identification.
\end_layout

\begin_layout Section
Issues
\end_layout

\begin_layout Subsection
Accuracy
\end_layout

\begin_layout Standard
We measure the accuracy of an IE task with two quantities:
\end_layout

\begin_layout Itemize

\emph on
precision
\emph default
: the percentage of correctly extracted entities among the extracted entities;
\end_layout

\begin_layout Itemize

\emph on
recall
\emph default
: the percentage of entities extracted among all the existing entities in
 the input source.
\end_layout

\begin_layout Standard
The main difficulties to achieving a good level of accuracy are:
\end_layout

\begin_layout Itemize
the availability of a great set of clues that might be very different in
 nature (e.
 g.
 orghographic properties, part of speech, typical words, etc.) and that might
 be difficult to combine;
\end_layout

\begin_layout Itemize
the difficulty of finding out missed extractions;
\end_layout

\begin_layout Itemize
the fact that with the advancement of research the extracted data structures
 keep increasing in complexity (for instance it is becoming more difficult
 to identify the boundaries of an entity in a text).
\end_layout

\begin_layout Standard
While we are able to reach a very good level of accuracy for entity extraction
 (
\begin_inset Formula $90\%$
\end_inset

), relationship extraction is still quite unreliable (
\begin_inset Formula $50-70\%$
\end_inset

 accuracy), mainly due to its intrinsic complexity, superior to that of
 the task of entity extraction.
\end_layout

\begin_layout Subsection
Running Time
\end_layout

\begin_layout Standard
In its initial phase IE was interesing only to research communities.
 With the enormous amount of data they need to process, companies are now
 concerned with IE too, and 
\emph on
scalability
\emph default
 has become a central issue, while many IE systems don't address the problem
 of efficiently carrying out extraction tasks with sufficient attention.
 Efficiency is influenced most notably by the efficiency of the following
 tasks:
\end_layout

\begin_layout Itemize
filtering documents in order to actually examine only the ones that have
 good chances to contain the desired information;
\end_layout

\begin_layout Itemize
focusing on the parts of a document that contain relevant information;
\end_layout

\begin_layout Itemize
processing steps, like database querying, that are typically very expensive
 and that might have to be performed on the selected pieces of input.
\end_layout

\begin_layout Standard
Recently many solutions have been proposed to target the scalability issue;
 one of these is indeed SystemT.
\end_layout

\begin_layout Section
Rule-Based Methods
\end_layout

\begin_layout Standard
Rule-based methods employ sets of predicates that are 
\begin_inset Quotes eld
\end_inset

fired
\begin_inset Quotes erd
\end_inset

 independently.
 When a portion of input text satisfies a predicate, the predicate's associated
 action is executed.
 A predicate can be represented in the following generic form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\textrm{"Contextual Pattern}\longrightarrow\textrm{Action"}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset

Contextual patterns are a way to identify entitities by exploiting their
 properties or the context in which they are usually met.
 The most common formalism used to express them is that of 
\emph on
regular expressions
\emph default
 over tokens of the input.
 Actions mark the entities that have been identified, and might consist
 in storing them in a database or adding delimiters directly in the text.
\begin_inset Newline newline
\end_inset

Most systems in this category present a cascaded structure: an input document
 goes through a series of processing phases, and the output of a phase is
 the input of the next one.
 A famous example is that of cascading grammars: formal grammars are evaluated
 in sequence on the input.
\end_layout

\begin_layout Subsection
Entity Extraction
\end_layout

\begin_layout Standard
As I said, a contextual pattern seeks for (groups of) tokens that have certain
 features.
 In the case of entity extraction, features can be classified in the following
 categories:
\end_layout

\begin_layout Itemize
string representation;
\end_layout

\begin_layout Itemize
orthography (e.g.
 small case, mixed case, number, etc.);
\end_layout

\begin_layout Itemize
part of speech;
\end_layout

\begin_layout Itemize
list of dictionaries they're contained into;
\end_layout

\begin_layout Itemize
annotation obtained in previous phases.
\end_layout

\begin_layout Standard
Rules can be hand-coded by experts or learned through learning algorithms.
 In the second case the goal is to cover each of the entities of interest
 in the training set with at least one rule.
 The obtained rules should have good recall and precision on new input.
 Moreover, when learning a set of rules, we would like to achieve a good
 level of 
\emph on
generalizability
\emph default
, that is: we would like to find the minimum set of rules accounting for
 the maximum portion of training data, with high precision.
 There are two main strategies for rule learning: 
\emph on
bottom-up
\emph default
 (start from very specific rules and make them more and more general) and
 
\emph on
top-down
\emph default
 (start with rules covering all existing instances, then specialize them).
\end_layout

\begin_layout Subsubsection
Example Rules
\end_layout

\begin_layout Standard
For the examples I use an idealized syntax, as in REF.
\end_layout

\begin_layout Example
Consider the task of identifying all mentions ISO standards in a text.
 A rule for this purpose could be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{multline}
\left(\left\{ \textrm{String}=\textrm{"ISO"}\right\} \left\{ \textrm{String}=\textrm{"/IEC"}\right\} \left\{ \textrm{?}\right\} \left\{ \textrm{String}=\textrm{"/ASTM"}\right\} \left\{ \textrm{?}\right\} \right.\\
\left.\left\{ \textrm{Orthography type}=\textrm{number}\right\} \left\{ \left\{ \textrm{String}=\textrm{":"}\right\} \left\{ \textrm{Orthography type}=\textrm{number}\right\} \right\} \left\{ \textrm{?}\right\} \right)\\
\longrightarrow\textrm{ISO Standards}
\end{multline}

\end_inset


\end_layout

\begin_layout Standard
a
\end_layout

\begin_layout Example
Multiple entities can be matched at once.
 Imagine we need to find mentions of (simple) street addresses in a text
 consisting of a street name and a street number.
 A rule that matches the name and number separatedly could be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{multline}
\left(\left\{ \textrm{Orthography type}=\textrm{mixed case word}\right\} \left\{ \textrm{*}\right\} \right)\textrm{: Name}\left(\left\{ \textrm{String}=\textrm{","}\right\} \right)\\
\left(\left\{ \textrm{Orthography type}=\textrm{number}\right\} \right)\textrm{: Number}\\
\longrightarrow\textrm{Street Name}=:\textrm{Name, }\textrm{Street Number}=:\textrm{Number}
\end{multline}

\end_inset


\end_layout

\begin_layout Subsection
Relationship Extraction
\end_layout

\begin_layout Standard
When exctracting relationship between entities, we might face three types
 of specific tasks:
\end_layout

\begin_layout Itemize
given a pair of entities, find the relationship between them;
\end_layout

\begin_layout Itemize
given an entity and a relationship, 
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "conclusion.lyx"

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "xampl"
options "apalike"

\end_inset


\end_layout

\begin_layout Standard
\start_of_appendix
\begin_inset CommandInset include
LatexCommand include
filename "appendix.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset


\end_layout

\end_body
\end_document
