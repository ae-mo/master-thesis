%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,english,american,draftfoot]{ulb_thesis}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{float}
\usepackage{url}
\usepackage{slashed}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{makeidx}
\makeindex

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
 \input{ulb_ntheorem.std}
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
 \setlength{\leftmargin}{\labelwidth}
 \addtolength{\leftmargin}{\labelsep}
 \renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}

\makeatother

\usepackage{babel}
\addto\captionsenglish{\renewcommand{\algorithmname}{Algorithm}}

\begin{document}
\selectlanguage{english}%

\title{Engineering a Runtime System for AQL}

\selectlanguage{american}%

\author{Andrea Morciano}


\degreeaward{Docteur en XXX\\
(Département XXX, Faculté XXX)}
\maketitle
\begin{dedication}
To my parents.\end{dedication}
\begin{acknowledgments}
Thank you, my advisor!
\end{acknowledgments}
\vspace*{4cm}


\emph{``A great citation here}''

\begin{flushright}
X
\par\end{flushright}
\begin{abstract}
abstract of the thesis
\end{abstract}
\tableofcontents{}

\listoffigures


\listoftables


\mainmatter

\include{intro}


\chapter{Information Extraction}


\section{Definition}

Information Extraction (IE) is the discipline that addresses the task
of extracting structured information from unstructured sources automatically.
Sources usually take the form of text documents. The most explored
aspect of IE is the extraction of \emph{named entities.} Another main
topic, that has become object of research only in recent years, is
the extraction of \emph{relationships} between entities. IE is a field
with contributions from many different communities: Machine Learning,
Information Retrieval, Database, Web, Document Analysis. The interest
in towards it is motivated by the evergrowing amount of data that
is generated by our society, that is at a point in which manual analysis
is infeasible. Thus IE promises to bring value to many application
domains, most notably the enterprise world and the Web. There are
two prominent approaches to IE: \emph{rule-based }and \emph{statistical}.


\section{Example Applications}


\paragraph{News Tracking}

The activity of tracking events in news articles. It can result in
a lot of useful services, like automatic creation of multimedia news,
linking articles to information pages on the entities found, etc.


\paragraph{Data Cleaning}

Extracting structured forms from flat data strings (containing, e.g.,
addresses). It allows more effective decuplication of information,
among the other things.


\paragraph{Citation Databases}

Articles, conferences sites, individual research sites and similar
are explored to obain formatted citations of publications, later stored
in publicly accessible databases. They are capable to forward references
and may provide aggregate statistics and scoring information. See
for instance Google Scholar (\url{https://scholar.google.com/}).


\paragraph{Relationship Web Search}

Relationship extraction would be a very useful feature to integrate
into web search engines, as the keyword search that they offer at
present time is only good for entity identification.


\section{Issues}


\subsection{Accuracy}

We measure the accuracy of an IE task with two quantities:
\begin{itemize}
\item \emph{precision}: the percentage of correctly extracted entities among
the extracted entities;
\item \emph{recall}: the percentage of entities extracted among all the
existing entities in the input source.
\end{itemize}
The main difficulties to achieving a good level of accuracy are:
\begin{itemize}
\item the availability of a great set of clues that might be very different
in nature (e. g. orghographic properties, part of speech, typical
words, etc.) and that might be difficult to combine;
\item the difficulty of finding out missed extractions;
\item the fact that with the advancement of research the extracted data
structures keep increasing in complexity (for instance it is becoming
more difficult to identify the boundaries of an entity in a text).
\end{itemize}
While we are able to reach a very good level of accuracy for entity
extraction ($90\%$), relationship extraction is still quite unreliable
($50-70\%$ accuracy), mainly due to its intrinsic complexity, superior
to that of the task of entity extraction.


\subsection{Running Time}

In its initial phase IE was interesing only to research communities.
With the enormous amount of data they need to process, companies are
now concerned with IE too, and \emph{scalability} has become a central
issue, while many IE systems don't address the problem of efficiently
carrying out extraction tasks with sufficient attention. Efficiency
is influenced most notably by the efficiency of the following tasks:
\begin{itemize}
\item filtering documents in order to actually examine only the ones that
have good chances to contain the desired information;
\item focusing on the parts of a document that contain relevant information;
\item processing steps, like database querying, that are typically very
expensive and that might have to be performed on the selected pieces
of input.
\end{itemize}
Recently many solutions have been proposed to target the scalability
issue; one of these is indeed SystemT.


\section{Entity Extraction\label{sec:Entity-Extraction}}

Named entities are elements of interest in a text. Example of entities
are person names, street addresses, institutions, countries, and so
on. In this section and in the next one, I assume that the output
of an extraction task is a series of labels inserted into an input
text document (that becomes \emph{annotated}), although there are
other possibilities.


\subsection{Rule-based Methods}

Rule-based methods employ sets of predicates that are ``fired''
independently. When a portion of input text satisfies a predicate,
the predicate's associated action is executed. A predicate can be
represented in the following generic form:

\begin{equation}
\textrm{"Contextual Pattern}\longrightarrow\textrm{Action"}
\end{equation}
\\
Contextual patterns are a way to identify entitities by exploiting
their properties or the context in which they are usually met. The
most common formalism used to express them is that of \emph{regular
expressions} over tokens of the input. Actions mark the entities that
have been identified, and might consist in storing them in a database
or adding delimiters directly in the text.\\
Most systems in this category present a cascaded structure: an input
document goes through a series of processing phases, and the output
of a phase is the input of the next one. A famous example is that
of cascading grammars: formal grammars are evaluated in sequence on
the input.

As I said, a contextual pattern seeks for (groups of) tokens that
have certain features. In the case of entity extraction, features
can be classified in the following categories:
\begin{itemize}
\item string representation;
\item orthography (e.g. small case, mixed case, number, etc.);
\item part of speech;
\item list of dictionaries they're contained into;
\item annotation obtained in previous phases.
\end{itemize}
Rules can be hand-coded by experts or learned through learning algorithms.
In the second case the goal is to cover each of the entities of interest
in the training set with at least one rule. The obtained rules should
have good recall and precision on new input. Moreover, when learning
a set of rules, we would like to achieve a good level of \emph{generalizability},
that is: we would like to find the minimum set of rules accounting
for the maximum portion of training data, with high precision. There
are two main strategies for rule learning: \emph{bottom-up} (start
from very specific rules and make them more and more general) and
\emph{top-down} (start with rules covering all existing instances,
then specialize them).


\subsubsection{Example Rules}

For the examples I use an idealized syntax, as in REF.
\begin{example}
Consider the task of identifying all mentions ISO standards in a text.
A rule for this purpose could be:

\begin{multline}
\left(\left\{ \textrm{String}=\textrm{"ISO"}\right\} \left\{ \textrm{String}=\textrm{"/IEC"}\right\} \left\{ \textrm{?}\right\} \left\{ \textrm{String}=\textrm{"/ASTM"}\right\} \left\{ \textrm{?}\right\} \right.\\
\left.\left\{ \textrm{Orthography type}=\textrm{number}\right\} \left\{ \left\{ \textrm{String}=\textrm{":"}\right\} \left\{ \textrm{Orthography type}=\textrm{number}\right\} \right\} \left\{ \textrm{?}\right\} \right)\\
\longrightarrow\textrm{ISO Standards}
\end{multline}

\end{example}

a
\begin{example}
Multiple entities can be matched at once. Imagine we need to find
mentions of (simple) street addresses in a text consisting of a street
name and a street number. A rule that matches the name and number
separatedly could be:

\begin{multline}
\left(\left\{ \textrm{Orthography type}=\textrm{mixed case word}\right\} \left\{ \textrm{*}\right\} \right)\textrm{: Name}\left(\left\{ \textrm{String}=\textrm{","}\right\} \right)\\
\left(\left\{ \textrm{Orthography type}=\textrm{number}\right\} \right)\textrm{: Number}\\
\longrightarrow\textrm{Street Name}=:\textrm{Name, }\textrm{Street Number}=:\textrm{Number}
\end{multline}

\end{example}


\subsection{Statistical Methods}

Statistical methods aim to decompose the source, assigning a label
to each element in the decomposition. We distinguish between three
types of statistical models:
\begin{itemize}
\item \emph{Token-level models}: they assign a label to each token of the
source. Since entities are usually comprised of multiple adjacent
tokens, the tags used are of the forms ``entity\_begin'', ``entity\_continue'',
``entity\_end'';
\item \emph{Segment-level models}: they try to find the best segmentation
of the source text;
\item \emph{Grammar-based models: }they use formal grammars, outputting
parse trees. All the valid parses are considered for an input document,
assigning a score to each. The parse with the highest score is retained.
\end{itemize}
I now give a brief description of Token-level Models and Segment-level
Models.


\subsubsection{Token-Level Models\label{sub:Token-Level-Models}}


\paragraph{Features}

Clues are of the form 
\begin{equation}
f:\left(x,y,i\right)\longmapsto\mathbb{R}
\end{equation}
where $x$ is a sequence of tokens, $i$ is a position in $x$ and
$y$ is a candidate label for the token at $i$. We distinguish between
these types of features:
\begin{itemize}
\item \emph{word features};
\item \emph{orthographic features;}
\item \emph{dictionary lookup features.}
\end{itemize}

\paragraph{Models for Labeling Token}

The best models are the ones that take into account dependencies between
tokens, among which we may find:
\begin{itemize}
\item \emph{ordered classifiers};
\item \emph{Hidden Markov models;}
\item \emph{Maximum Entropy Taggers;}
\item \emph{Conditional Markov Models;}
\item \emph{Conditional Random Fields }(the state of the art).
\end{itemize}

\subsubsection{Segment-Level Models}


\paragraph{Features}

In these models the label for a segment depends on the properties
of its token and on the previous segment. We can describe a segment
$s_{j}$ as:
\begin{equation}
s_{j}=\left(y_{i},l_{j},u_{j}\right)\label{eq:segment}
\end{equation}
where $y_{i}$ is the proposed label for $s_{j}$ and $l_{j},u_{j}$
are the start and end positions of $s_{j}$. Therefore, a feature
is of the form:
\begin{equation}
f\left(y_{i},y_{i-1},x,l_{j},u_{j}\right)
\end{equation}
where $x$ is the input sequence of tokens, $y_{i-1}$ is the proposed
label for the previous segment and the other symbols are defined as
for Equation \ref{eq:segment}. Besides token-level features (see
subsection \ref{sub:Token-Level-Models}), we can exploit the following
feature types:
\begin{itemize}
\item \emph{Similarity to an entity in a database;}
\item \emph{Length of the segment.}
\end{itemize}
There are also global segmentation models, that try to find the best
segmentation of a token sequence by maximizing a target function.


\section{Relationship Extraction}

When exctracting relationship between entities, we might face three
types of specific tasks:
\begin{itemize}
\item given a pair of entities, find the relationship between them;
\item given an entity $e$ and a relationship $r$, find all the other entities
$e'$ such that $\left(e,e'\right)\in r$;
\item given a big and open-ended input and a relationship $r$ find all
pairs of entities $e',e''$ such that $\left(e',e''\right)\in r$.
\end{itemize}

\subsection{Predicting the Relationship between a Entity Pair }

For the first task, we can exploit the following resources:
\begin{itemize}
\item \emph{surface tokens}: tokens that are usually placed between entities.
They are strong clues;
\item \emph{part of speech tags }(the most important being verbs);
\item \emph{syntactic parse tree}: allows grouping words in phrase types,
e.g. noun phrases, propositional phrases, and so on;
\item \emph{dependency graph}: it is a less expensive structure to compute
than the parse tree and it links a word to those that depend on it.
\end{itemize}
The main methods available to carry out the task are:
\begin{itemize}
\item \emph{Feature-based methods}, that simply transform the clues mentioned
above for usage by conventional classifier models;
\item \emph{Kernel-based methods}, that use kernel functions to encode the
similarity between two graphs;
\item \emph{Rule-based methods}, creating rules over structures around pairs
of entities.
\end{itemize}
The second task is a special case of the third one so I don't treat
it directly.


\subsection{Finding All Possible Entity Pairs Belonging to a Relationship}

The third task can be met especially when dealing with the Web. Usually
we can exploit the following resources to fulfill it:
\begin{itemize}
\item the \emph{types of arguments} of $r$ (that might need specific recognition
patterns);
\item a \emph{seed database} of pairs of entities belonging to $r$;
\item \emph{manually coded patterns}.
\end{itemize}
The generic procedure that is used in this case can be described with
these steps:
\begin{enumerate}
\item Use the seed database to learn the relevant extraction patterns;
\item Use the obtained patterns to define candidate triples of the form
$\left(e',e'',r\right)$;
\item Retain a subset of the candidate triples, using a statistical test.
\end{enumerate}
There exist also rule-based methods for the task. 


\chapter{SystemT and AQL}

In this chapter, I give a description of \emph{SystemT} and its extraction
rule language \emph{AQL} (Annotation Query Language), and of a new
way of evaluating AQL queries, that uses a formalism derived from
\emph{Finite State Automata}. Producing and analysing a concrete runtime
system for AQL queries that employs this new method is the object
of my thesis. Since SystemT is a rule-based system, I now focus only
on this category.


\section{SystemT}

As I mentioned in the previous chapter, scalability has now become
a central issue to IE. Companies now rely on IE for many tasks; a
prominent example is \emph{Business Intelligence}. Unfortunately,
many systems developed in the past don't address this concern correctly.
Traditionally, most rule-based system rely on cascading grammars:
formal grammars are executed in sequence on the input, each grammar
representing a stage that takes as input the ouput of the previous
one. Rules in such grammars are matched using regular expressions:
if a part of the input text satisfies the regular expression associated
with a rule, that rule is activated (i.e. ``fires'') and the corresponding
action is executed. Evaluating a grammar on a document tends to be
costly, because simply evaluating a single rule might require scanning
the whole document. On large datasets, the running time becomes enormous.
What's more, these kind of systems are not able to fulfill the expressivity
requirements of the complex extraction tasks.\\
SystemT was developed at IBM to address these issues. This system
is based on a new approach to extraction rules: the \emph{algebraic
approach}. Here, data manipulations are viewed as operations in a
(relational) algebra. Extraction tasks are defined using \emph{annotators}
(see Section \ref{sec:Entity-Extraction}) whose rules are viewed
as \emph{queries} on input documents, that act as virtual databases.
Complex annotators are obtained by combining simple ones by means
of \emph{relational operators}. By doing so, all the optimization
techniques used in regular databases become available, but new techniques
are possible too, due to the characteristics of text documents. Another
advantage of SystemT is that it is capable to handle \emph{overlapping
rule matchings}, due to rulels being fired independently, which are
difficult to resolve in cascading grammars, where they tipically require
disambiguation policies that only partially solve the problem.\\
I now give an overview of SystemT's high-level structure. Then, I
talk about its data model, execution model and algebra.


\subsection{Architecture}

These are the main components of SystemT:
\begin{description}
\item [{Development~Environment:}] allows constructing annotators for
extraction tasks. Rules are expressed in AQL, and compiled into an
algebra. It supports an iterative development process.
\item [{Optimizer:}] seeks for the best query plan for an extraction task,
evaluating the most convenient optimization techniques in a cost-based
manner.
\item [{Runtime~Environment:}] given a query plan, it instantiates the
physical operators corresponding to the logical ones in the plan,
then it proceeds evaluating it on input documents.
\end{description}
Once the development of an annotator is complete, it is \emph{published}
to the optimizer and runtime. After optimization, the runtime evaluates
it on a continuous stream of documents.


\subsection{Data Model\label{sub:Data-Model}}

SystemT uses an \emph{object-relational} data model for annotations
on a text document, that allows applying logical operators over it,
that can be composed. There is an important assumption to mention
before continuing: an extraction task over a set of documents is performed
one document at a time. This means that any relationships between
entities in different documents are disregarded. This assumption is
crucial to some optimization techniques that SystemT uses. While there
exist tasks where considering these relationships would be useful
(think of the Web), still a large number of relevant tasks can be
carried out this way. In the following, I define the basic data types
of SystemT's data model. \\
I consider a finite alphabet $\varSigma$ of symbols (characters).
$\sum^{*}$ denotes the set of all strings of finite length over $\sum^{*}$.
A document is modeled as one such string. 
\begin{definition}
A document is a string $s\in\sum^{*}$.
\end{definition}

\noindent The most basic data type is the \emph{span}.
\begin{definition}
Given a string $s=\sigma_{1}...\sigma_{n}$ where $\forall i$, $\sigma_{i}\in\Sigma$,
with length$\left|s\right|=n$ and whose characters are indexed in
the natural way, a span is a substring $\left[i,j\right\rangle $
, where $i,j$ are indices of $s$ satisfying $1\leq i\leq j\leq n+1$.
A span of $s$ is also denoted as $s_{\left[i,j\right\rangle }$.
\end{definition}

\noindent Spans can be aggregated in \emph{tuples}, which are finite
sequences of spans\emph{. }Let us denote the set of all possible spans
of a string $s$ by $\textrm{Spans}\left(s\right)$ and by $\textrm{SVars}$
an infinite set of span variables, which can be assigned spans. A
$\left(V,s\right)-\textrm{tuple}$ is defined as follows:
\begin{definition}
Given a set $V\subseteq\textrm{SVars}$, $V$ being finite, and a
string $s\in\sum^{*}$, a $\left(V,s\right)-\textrm{tuple}$ is a
mapping $\mu:V\longmapsto\textrm{Spans}\left(s\right)$. When $V$
is clear from the context, we might call $\mu$ simply a $s-\textrm{tuple}$.
\end{definition}

\noindent A set of tuples is called a \emph{relation. }Here, I focus
on \emph{span relations}, which I formally define as $\left(V,s\right)-\textrm{relations}$.
\begin{definition}
\label{span-relation}A $\left(V,s\right)-\textrm{relation}$ is a
set of $\left(V,s\right)-\textrm{tuples}$. As before, we can speak
of $s-\textrm{relation}$ when $V$ is clear.
\end{definition}

\noindent Each operator in the algebra takes one or more span relations
as input and outputs a single span relation.


\subsection{Execution Model\label{sub:Execution-Model}}

A single document is conceived as a \emph{local annotation database},
to which annotators are applied in order to build \emph{views}. In
general, a local database fits into main memory. Local databases are
contained in a \emph{global annotation database}. The runtime of SystemT
takes a global database and it annotates its local databases. The
procedure is described by Algorithm \ref{alg:Annotating-all-local}.

\begin{algorithm}
$E\longleftarrow\left\{ \textrm{algebra expression}\right\} $

for localDB in globalDB do

begin
\begin{enumerate}
\item $\left\{ \textrm{Read localDB into main memory}\right\} $
\item $R\longleftarrow E\left(\textrm{localDB}\right)$
\item $\left\{ \textrm{Add \ensuremath{R} to localDB}\right\} $
\item $\left\{ \textrm{Write modified localDB to disk}\right\} $
\end{enumerate}
\caption{\label{alg:Annotating-all-local}Annotating all local databases in
a global database (taken from REF).}


\end{algorithm}


\noindent In this procedure, step 2 in the for loop is the most expensive.


\subsection{Algebra of Operators \label{sub:Algebra-of-Operators}}

The operators of SystemT's algebra can be classified in three groups:
\begin{itemize}
\item \emph{relational operators;}
\item \emph{span extraction operators;}
\item \emph{span aggregation operators.}
\end{itemize}
In addition, there exist some \emph{span selection predicates} that
are used for span selection.


\subsubsection{Relational Operators}

Relational operators are the usual operators of relational algebra
that appear in classical database query plans. Important examples
are:
\begin{itemize}
\item \emph{selection} ($\sigma$);
\item \emph{projection }($\pi$);
\item \emph{Cartesian product }($\times$);
\item \emph{Union} ($\cup$);
\item \emph{Intersection} ($\cap$).
\end{itemize}

\subsubsection*{Span Extraction Operators}

Loosely speaking, span extraction operators take a pattern and a document
as input and output the maximal set of spans that match that pattern.
There are two main span extraction operators:
\begin{lyxlist}{00.00.0000}
\item [{\emph{standard~regular~expression~matcher~($\varepsilon_{re}$)}:}] this
operator takes a regular expression $r$ as input and it identifies
all non-overlapping matchings of $r$ in the current document, from
left to right.
\item [{\emph{dictionary~matcher~($\varepsilon_{d}$)}:}] this operator
outputs all the spans that match some entry in a given dictionary.
\end{lyxlist}
Although the dictionary matcher might seem useless since there is
a regular expression matcher, it has some advantages over it, as the
fact that it can find overlapping matchings or that it enforces the
semantics of word boundaries.


\subsubsection*{Span Aggregation Operators}

Span aggregation operators are used to aggregate spans in a meaningful
way. They are of two types:
\begin{itemize}
\item \emph{Consolidation}: they are used to coalesce overlapping spans
that were matched using patterns for the same concept. They are: 

\begin{lyxlist}{00.00.0000}
\item [{\emph{containment~consolidation~($\varOmega_{c}$)}:}] it discards
a span if it is fully contained into another one.
\item [{\emph{overlap~consolidation~($\varOmega_{o}$)}:}] it merges
spans that overlap repeatedly.
\end{lyxlist}
\item \emph{Block ($\beta$)}: it matches a series of spans, each at a distance
from its neighbor span(s) that is not superior to a threshold. It
is thought to identify regularity. It is tuned by two parameters:
a \emph{distance constraint} to control regularity and a \emph{count
constraint }that establishes the minimum number of spans in a block.
\end{itemize}

\subsubsection{Span Selection Predicates}

\noindent Consider two spans $s_{1},s_{2}$. The main span predicates
that may be used for selection are the following:
\begin{lyxlist}{00.00.0000}
\item [{$s_{1}\preceq_{d}s_{2}$}] \noindent when $s_{1},s_{2}$ do not
overlap, $s_{1}$ precedes $s_{2}$ and there are less than $d$ characters
between them;
\item [{$s_{1}\simeq s_{2}$}] when the two spans overlap;
\item [{$s_{1}\subset s_{2}$}] when $s_{1}$ is strictly contained in
$s_{2}$;
\item [{$s_{1}=s_{2}$}] when $s_{1}$ equals $s_{2}$.
\end{lyxlist}

\subsection{Optimization Techniques}

As I mentioned in the introduction of this chapter, SystemT can make
use of the optimization techniques from traditional database systems,
but there exist some peculiar aspects of SystemT and span extraction
tasks that enable new optimization methods.
\begin{remark}
The effect of document-at-a-time processing is that the span relations
produced and consumed for a single document by operators are very
small in size and often empty.\label{small-relations}
\end{remark}


\begin{remark}
Evaluating an annotator on a large set of document is a \emph{CPU-intensive
process}. This is because the running time is by far dominated by
the execution of the operators $\varepsilon_{re}$ and $\varepsilon_{d}$,
that are applied to each document in an input set.
\end{remark}


\begin{remark}
Spans are nothing but \emph{intervals}, so we can exploit \emph{interval
algebra}.\label{interval-algebra}
\end{remark}



\noindent With Remark \ref{small-relations} and Remark \ref{interval-algebra}
in mind, running time can be reduced in a number of ways. I present
them briefly.
\begin{description}
\item [{Regular~Expression~Strength~Reduction}] Some classes of regular
expressions, as defined in the POSIX standard, are executed more efficiently
by using \emph{specialized engines }that are able to improve performance.
For example, an expression that looks for a finite number of strings
in a text is evaluated more efficiently by a string-matching engine.
\item [{Shared~Dictionary~Matching~(SDM)}] Dictionary lookups are usually
very expensive, as we need to consult the dictionary thousand of times
in a typical setting. Instead of evaluating each $\varepsilon_{d}$
operator in an extraction task independently for each input document,
it is evaluated once and for all at the beginning of the process,
and the obtained matches are shared among the single documents.
\item [{Conditional~Evaluation~(CE)}] As we know, an annotator is evaluated
indipendently on each input document. Thus, by employing some heuristic,
it can be guessed if a (sub)query will give any matches in a document
without loss of generality, and in case it does not, it is not evaluated
on it.
\item [{Restricted~Span~Extraction~(RSE)}] It consists in executing
expensive operations on selected regions of a document. It is used
for \emph{join} operators involving dictionary matching operators
and/or a regular expression matching operators in their argments.
One input operator to a join is evaluated on the whole document, while
the other operators are modified to consider only some neighborhood
of the results from the first one. These neighborhoods are established
by some ad hoc heuristic.
\end{description}
The techniques described allow the use of a \emph{cost-based plan
optimizer}: in a query plan, the subgraphs suitable for optimization
are identified, and all the possible optimized plans for them are
formulated. In the end, the best ones are retained. Results of sample
experiments on a large dataset are decribed in REF and REF.


\section{AQL}

AQL is the concrete language used by SystemT to express annotators,
designed to support the execution model I described in Subsection
\ref{sub:Execution-Model}. It is a declarative language with a syntax
very similar to that of SQL. It supports all the operators that I
presented in Subsection \ref{sub:Algebra-of-Operators}. When coding
an extraction task in AQL, we are able to build a series of views
of a document, that are of progressively higher level, and can be
based on lower-level views. The content of a view corresponds with
annotations in the text. An input document is modeled as a view too,
which is provided by default. The main advantages of AQL are:
\begin{itemize}
\item it allows formulating \emph{complex low-level }patterns in a declarative
fashion;
\item it enables \emph{modularization }and \emph{reuse} of the queries,
making development and maintance of \emph{complex high-level structures}
easier.
\end{itemize}

\section{A Formalism for AQL's Core: VStack and VSet Automata}

AUTHORS describe in REF a formal model that captures the core functionality
of AQL. They show a way to represent annotators expressed in AQL by
means of modified finite state automata, namely \emph{VStack} and
\emph{VSet automata}. In my work, I define and implement a runtime
system based on this new formalism. I now describe the model and discuss
the relative expressive power of its main elements. First of all,
we need to be more precise on some basic concepts.


\subsection{Basic Definitions}

I consider $\varSigma$ and $\varSigma^{\ast}$, defined as in Subsection
\ref{sub:Data-Model}. Let us start with the definition of a language.
\begin{definition}
A language L is a subset of $\varSigma^{\ast}$.
\end{definition}

\noindent Now we can state formally define regular expressions, by
giving their language.
\begin{definition}
Regular expressions over $\varSigma$ are those that belong to the
language $\gamma$ defined as:
\begin{equation}
\gamma:=\textrm{Ø}\mid\epsilon\mid\sigma\mid\gamma\vee\gamma\mid\gamma\cdot\gamma\mid\gamma^{\ast}
\end{equation}


\noindent where:
\begin{itemize}
\item $\slashed{O}$ is the empty language;
\item $\epsilon$ is the empty string;
\item $\sigma\in\varSigma$;
\item $\vee$ is the ordinary disjunction operator;
\item $\cdot$ is the concatenation operator;
\item $\ast$ is the Kleene Closure.
\end{itemize}
\end{definition}

\noindent Additionally, we might use $\gamma^{+}$ as a shortcut for
$\gamma\cdot\gamma^{\ast}$, and $\varSigma$ as an abbreviation of
$\sigma_{1}\vee...\vee\sigma_{n}$ (with a slight abuse of notation).
The language $\mathcal{L}\left(\gamma\right)$of a regular expression
$\gamma$ is the set of strings $\mathbf{s}$ over $\varSigma$ that
are matched by that expression. A language $L$ is \emph{regular}
if $L=\mathcal{L}\left(\gamma\right)$ for some regular expression
$\gamma$. We also need the definition of a \emph{string relation}.
\begin{definition}
A n-ary string relation is a subset of $\left(\varSigma^{\ast}\right)^{n}$.
\end{definition}

\noindent An interesting class of string relations is that of recognizable
relations, denoted as $\textrm{REC}$.
\begin{definition}
Given a k-ary string relation $R$, $R$ is recognizable if it is
representable by a finite union the form:
\begin{equation}
\bigcup L_{1}\times...\times L_{k}
\end{equation}


where each $L$$_{i}$ is a regular language.
\end{definition}

\noindent I have already defined span relations (Definition \ref{span-relation}).
They allow us to give a precise definition of annotators, by introducing
the concept of \emph{document spanner}.
\begin{definition}
Given a string $s$, a document spanner P is a function that maps
$s$ to a $\left(V,s\right)-\textrm{relation}$ $r$ , where $V:=\textrm{Svars}\left(P\right)$.
We have $r=P\left(s\right).$ We say $P$ is n-ary if $\left|V\right|=n$.
\end{definition}

\noindent I now present two types of spanners that will be useful
later on. The first one is that of \emph{Hierarchical Spanners}. First,
let us see when a $s-\textrm{tuple}$ is hierarchical.
\begin{definition}
\label{hierarchical-tuple}Given a string $s$, a document spanner
P and an $s-\textrm{tuple}$ $\mu\in P\left(s\right)$, $\mu$is hiearchical
if, for every $x,y\in\textrm{SVars}\left(P\right)$, one of the following
conditions holds:
\begin{itemize}
\item $\mu\left(x\right)\supseteq\mu\left(y\right);$
\item $\mu\left(x\right)\subseteq\mu\left(y\right)$;
\item $\mu\left(x\right)$ is disjoint from $\mu\left(y\right)$.
\end{itemize}
\end{definition}

\noindent The definition of \emph{hierarchical spanner} follows.
\begin{definition}
\label{hierarchical-spanner}Given a document spanner $P$, $P$ is
hierarchical if $\forall s\in\varSigma^{\ast}$, $\forall\mu\in P\left(s\right)$,
$\mu$ is hierarchical.
\end{definition}

\noindent The class of hierarchical spanners is denoted by $\mathbf{HS}$.
As it emerges from Definition \ref{hierarchical-tuple} and Definition
\ref{hierarchical-spanner}, a hierarchical spanner outputs only $s-\textrm{tuples}$
whose spans don't overlap. The second type of spanners I introduce
is that of \emph{Universal Spanners}. Some accessory definitions are
needed.
\begin{definition}
Given a string $s$ and a document spanner $P$, $P$ is total on
$s$ if $P\left(s\right)$ consists of all the possible $s-\textrm{tuples}$
on $\textrm{SVars}\left(P\right)$.
\end{definition}


\begin{definition}
Given a string $s$ and a document spanner $P$, $P$ is hierarchically
total on $s$ if $P\left(s\right)$ consists of all the possible hierarchical
$s-\textrm{tuples}$ on $\textrm{SVars}\left(P\right)$.
\end{definition}

\noindent There are two kinds of universal spanners: the \emph{universal
spanner} and the \emph{universal hierarchical spanner}.
\begin{definition}
Given a set of span variables $Y$$\subseteq\textrm{SVars}$, the
universal spanner $\Upsilon_{Y}$ over $Y$ is the unique document
spanner $P$ such that $\textrm{SVars}\left(P\right)=Y$ and $P$
is total on every string $s\in\varSigma^{\ast}$. 
\end{definition}


\begin{definition}
Given a set of span variables $Y$$\subseteq\textrm{SVars}$, the
universal hierarchical spanner $\Upsilon_{Y}^{H}$ over $Y$ is the
unique document spanner $P$ such that $\textrm{SVars}\left(P\right)=Y$
and $P$ is hierarchically total on every string $s\in\varSigma^{\ast}$. 
\end{definition}

\noindent I now present the formal spanner represantations described
in REF.


\subsection{Spanner Representations}

We saw in Subsection \ref{sub:Algebra-of-Operators} that the operations
used by SystemT and AQL to extract spans relations are regular expression
matching and dictionary matching. Here I focus on regular expressions.
AQL's regular expressions can be seen as usual regular expressions
enriched with \emph{capture variables}, that are nothing but the span
variables that constitute the span relations I defined. In what follows.
In REF, three formalisms are described that are able to model this
kind of modified regular expressions, namely:
\begin{itemize}
\item \emph{Regex Formulas;}
\item \emph{Variable Stack Automata;}
\item \emph{Variable Set Automata.}
\end{itemize}
These formalisms are also called \emph{primitive spanner representations}.


\subsubsection{Regex Formulas}

To define regex formula, I first introduce the concept of \emph{variable
regex.}
\begin{definition}
A variable regex is a regular expression with capture variables that
extends usual regular expressions in the following way:
\begin{equation}
\gamma:=\textrm{Ø}\mid\epsilon\mid\sigma\mid\gamma\vee\gamma\mid\gamma\cdot\gamma\mid\gamma^{\ast}\mid x\left\{ \gamma\right\} 
\end{equation}
 where:
\begin{itemize}
\item $x\in\textrm{SVars}$;
\item $x\left\{ \gamma\right\} $ means that we assign the result of the
evaluation of $\gamma$ to x.
\end{itemize}
\end{definition}

\noindent Evaluating a variable regex on a string produces a parse
tree over the alphabet $\Lambda=\varSigma\cup\textrm{SVars}\cup\left\{ \in,\vee,\cdot,\ast\right\} $.
A valid parse tree for a variable regex$\gamma$ is called a $\gamma-\textrm{parse}$.
We accept only those variable regex expressions whose parses have
only one occurence of each of their variables, otherwise the variable
assignment would remain unclear. Such expressions are referred to
as \emph{functional}.
\begin{definition}
A variable regex $\gamma$ is functional if $\forall s\in\varSigma^{\ast}$,
$\forall\gamma-\textrm{parse }t$ for $s$, $\forall x\in\textrm{SVars}\left(\gamma\right)$,
$x$ occurs exactly one time in $t$.
\end{definition}


\begin{definition}
A regex formula is a functional variable regex.
\end{definition}

\noindent The spanner represented by a regex formula $\gamma$ may
be denoted as $\left\llbracket \gamma\right\rrbracket $. We have
that $\textrm{SVars}\left(\left\llbracket \gamma\right\rrbracket \right)=\textrm{SVars}\left(\gamma\right)$,
and the span relation $\left\llbracket \gamma\right\rrbracket \left(s\right)$
is the set $\left\{ \mu^{p}\mid p\textrm{ is a }\gamma-\textrm{parse for \ensuremath{s}}\right\} $,
where $\mu^{p}$ is a tuple defined by a parse $p$. The class of
regex formulas is referred to as $\textrm{RGX}$.


\subsubsection{Variable Stack Automata}

Variable stack automata (VStack Automata or vstk-automata for short)
are representations of document spanners by means of modified finite
state automata (FAs). Basically, a FA is augmented with a \emph{stack
of span variables}. A variable is pushed on the stack when its corresponding
span is opened, and popped when it is closed. The formal definition
of a vstk-automaton follows.
\begin{definition}
\label{vstk-aut}A Variable Stack Automaton is a tuple $\left(Q,q_{0},q_{f},\delta\right)$,
where:
\begin{itemize}
\item $Q$ is a finite set of states;
\item $q_{0}\in Q$ is the initial state;
\item $q_{f}\in Q$ is the accepting state;
\item $\delta$ is a finite transition relation, containing triples of the
forms $\left(q,\sigma,q'\right)$, $\left(q,\epsilon,q'\right)$,
$\left(q,x\vdash,q'\right)$, $\left(q,\dashv,q'\right)$, where:

\begin{itemize}
\item $q,q'\in Q$;
\item $\sigma\in\varSigma$;
\item $x\in SVars$;
\item $\vdash$ is the push symbol;
\item $\dashv$ is the pop symbol.
\end{itemize}
\end{itemize}
\end{definition}

\noindent Notice that we don't need to specify which variable we want
to pop, as it is naturally the last that was pushed on the stack.
Given a vstk-automaton $A$, the set of variables that appear in its
transitions is denoted as $\textrm{SVars}\left(A\right)$. Next I
give the definitions of a \emph{configuration }and of a \emph{run}
of a vstk-automaton.
\begin{definition}
\label{vstk-conf}Given a string $s$ with length $\left|s\right|=n$
and a vstk-automaton $A$ , a configuration of $A$ is a tuple $c=\left(q,\overrightarrow{v},Y,i\right)$,
where:
\begin{itemize}
\item $q\in Q$ is the current state;
\item $\overrightarrow{v}$ is the current variable stack;
\item $Y\in Vars$$\left(A\right)$ is the set of available variables (those
not already pushed on the stack);
\item $i\in\left\{ 1,...,n+1\right\} $ is the position of the next character
to be read in $s$.
\end{itemize}
\end{definition}

\noindent Here, as for regex formulas, we want the variable assignment
to be clear, so once a variable is pushed on the stack, it is removed
from the set of available variables, thus it can be pushed only once.
For the rest, a run of a vstk-automaton is similar to those of ordinary
FAs.
\begin{definition}
Given a string $s$ and a vstk-automaton $A$, a run $\rho$ of $A$
on $s$ is a sequence of configurations $c_{0},...,c_{m}$ such that:
\begin{itemize}
\item $c_{0}=\left(q_{0},\epsilon,\textrm{SVars}\left(A\right),1\right)$;
\item $\forall j\in\left\{ 0,...,m-1\right\} $, for $c_{j}$=$\left(q_{j},\overrightarrow{v_{j}},Y_{j},i_{j}\right)$,
$c_{j+1}$=$\left(q_{j+1},\overrightarrow{v_{j+1}},Y_{j+1},i_{j+1}\right)$
one of the following holds:

\begin{itemize}
\item $\overrightarrow{v_{j+1}}=\overrightarrow{v_{j}}$, $Y_{j+1}=Y_{j}$
and either:

\begin{itemize}
\item $i_{j+1}=i_{j}+1$, $\left(q_{j},s_{i_{j}},q_{j+1}\right)\in\delta$;
\item $i_{j+1}=i_{j}$, $\left(q_{j},\in,q_{j+1}\right)\in\delta$.
\end{itemize}
\item $i_{j+1}=i_{j}$ and for some $x\in\textrm{SVars}\left(A\right)$
either:

\begin{itemize}
\item $\overrightarrow{v_{j+1}}=\overrightarrow{v_{j}}\cdot x$, $x\in Y_{j}$,
$Y_{j+1}=Y_{j}\setminus\left\{ x\right\} $, $\left(q_{j},x\vdash,q_{j+1}\right)\in\delta$
(x is pushed on the stack);
\item $\overrightarrow{v_{j}}=\overrightarrow{v_{j+1}}\cdot x$, $x\in Y_{j}$,
$Y_{j+1}=Y_{j}$, $\left(q_{j},\dashv,q_{j+1}\right)\in\delta$ (a
variable is popped from the stack).
\end{itemize}
\end{itemize}
\end{itemize}
\end{definition}


\begin{definition}
Given a string with length $\left|s\right|=n$ and a vstk-automaton
$A$, a run $\rho=c_{0},...,c_{m}$ of $A$ on $s$ is accepting if
$c_{m}=\left(q_{f},\epsilon,\textrm{Ø},n+1\right)$.
\end{definition}

\noindent The set of all possible accepting runs of a vstk-automaton
$A$ on a string $s$ is denoted as $\textrm{ARuns}\left(A,s\right)$.
The spanner represented by $A$ may be referred to as $\left\llbracket A\right\rrbracket $.
We have that $\textrm{SVars}\left(\left\llbracket A\right\rrbracket \right)=\textrm{SVars}\left(A\right)$,
and the span relation $\left\llbracket A\right\rrbracket \left(s\right)$
is the set $\left\{ \mu^{\rho}\mid\rho\in\textrm{ARuns}\left(A,s\right)\right\} $,
where $\mu^{\rho}$ is a tuple defined by a run $\rho$. In particular,
for every variable $x\in\textrm{SVars}\left(A\right)$, $\mu^{\rho}\left(x\right)$
is the span $\left[i_{b},i_{e}\right\rangle $, where:
\begin{itemize}
\item $c_{b}$=$\left(q_{b},\overrightarrow{v_{b}},Y_{b},i_{b}\right)$
is the unique configuration of $\rho$ where $x$ appears in the stack
for the fist time;
\item $c_{e}$=$\left(q_{e},\overrightarrow{v_{e}},Y_{e},i_{e}\right)$
is the unique configuration of $\rho$ where $x$ appears in the stack
for the last time.
\end{itemize}
\noindent The class of variable stack automata is called $\textrm{VA}_{\textrm{stk}}$.


\subsubsection{Variable Set Automata}

Variable Set Automata (VSet Automata or vset-automata for short) are
another formalism for representing document spanners that is based
on FAs. Vset-automata are defined in a very similar way to that of
vstk-automata. The main differences are:
\begin{itemize}
\item the stack of span variables is replaced by a \emph{set;}
\item since no order is defined on the variables in the set, when we close
a variable, we need to specify which one.
\end{itemize}
I now give a formal definition of a vset-automaton.
\begin{definition}
A variable set automaton is a tuple $\left(Q,q_{0},q_{f},\delta\right)$,
where:
\begin{itemize}
\item $Q$, $q_{0}$ and $q_{f}$ are defined as in Definition \ref{vstk-aut};
\item $\delta$ is the same as in Definition \ref{vstk-aut}, except that
it has triples of the form $\left(q,\dashv x,q'\right)$, with $x\in\textrm{SVars}$,
instead of those of the form $\left(q,\dashv,q'\right)$.
\end{itemize}
\end{definition}

\noindent We also need to slightly modify the definitions of configuration
and run with respect to those of a vstk-automaton.
\begin{definition}
Given a string $s$ with length $\left|s\right|=n$ and a vset-automaton
$A$ , a configuration of $A$ is a tuple $c=\left(q,V,Y,i\right)$,
where:
\begin{itemize}
\item $q$, $i$ are defined as in Definition \ref{vstk-conf};
\item $V\subseteq\textrm{Vars}\left(A\right)$ is the active variable set;
\item $Y\in Vars$$\left(A\right)$ is the set of available variables (those
not already placed in the set).
\end{itemize}
\end{definition}


\begin{definition}
Given a string $s$ and a vset-automaton $A$, a run $\rho$ of $A$
on $s$ is a sequence of configurations $c_{0},...,c_{m}$ such that:
\begin{itemize}
\item $c_{0}=\left(q_{0},\textrm{Ø},\textrm{SVars}\left(A\right),1\right)$;
\item $\forall j\in\left\{ 0,...,m-1\right\} $, for $c_{j}$=$\left(q_{j},V_{j},Y_{j},i_{j}\right)$,
$c_{j+1}$=$\left(q_{j+1},V_{j+1},Y_{j+1},i_{j+1}\right)$ one of
the following holds:

\begin{itemize}
\item $V_{j+1}=V_{j}$, $Y_{j+1}=Y_{j}$ and either:

\begin{itemize}
\item $i_{j+1}=i_{j}+1$, $\left(q_{j},s_{i_{j}},q_{j+1}\right)\in\delta$;
\item $i_{j+1}=i_{j}$, $\left(q_{j},\in,q_{j+1}\right)\in\delta$.
\end{itemize}
\item $i_{j+1}=i_{j}$ and for some $x\in\textrm{SVars}\left(A\right)$
either:

\begin{itemize}
\item $x\in Y_{j}$, $V_{j+1}=V_{j}\cup\left\{ x\right\} $, $Y_{j+1}=Y_{j}\setminus\left\{ x\right\} $,
$\left(q_{j},x\vdash,q_{j+1}\right)\in\delta$ ($x$ is inserted into
the set);
\item $x\in V_{j}$, $V_{j+1}=V_{j}\setminus\left\{ x\right\} $, $Y_{j+1}=Y_{j}$,
$\left(q_{j},\dashv x,q_{j+1}\right)\in\delta$ ($x$ is removed from
the set).
\end{itemize}
\end{itemize}
\end{itemize}
\end{definition}


\begin{definition}
Given a string with length $\left|s\right|=n$ and a vset-automaton
$A$, a run $\rho=c_{0},...,c_{m}$ of $A$ on $s$ is accepting if
$c_{m}=\left(q_{f},\textrm{Ø},\textrm{Ø},n+1\right)$.
\end{definition}

\noindent Given a string $s$ and a vset-automaton $A$, $\textrm{ARuns}\left(A,s\right)$and
$\left\llbracket A\right\rrbracket $ are defined as for vstk-automata.
The class of variable set automata is called $\textrm{VA}_{\textrm{stk}}$.


\subsection{Algebras of Spanners\label{sub:Algebras-of-Spanners}}

Besides mere span extraction, AQL offers the capability to combine,
transform and filter extracted tuples by using a series of relational
operators. Here, I introduce the relational operators for spanners,
described in REF, that are considered to capture the core relational
operations of AQL. They are:
\begin{itemize}
\item \emph{Union }( $\cup$);
\item \emph{Projection }($\pi$);
\item \emph{Natural Join} ($\bowtie$);
\item \emph{String Selection} ($\varsigma$).
\end{itemize}
A finite set of spanner operators forms a \emph{spanner algebra}.
In the following, give definitions for each of the listed spanner
operators.


\subsubsection{Union}

Before giving the definition of the union operator, we need to introduce
the concept of \emph{union compatible spanners.}
\begin{definition}
Given two document spanner $P_{1}$ and $P_{2}$, they are union compatible
if and only if $\textrm{SVars}\left(P_{1}\right)=\textrm{SVars}\left(P_{2}\right)$.
\end{definition}

\noindent The definition of union of two spanners is as follows.
\begin{definition}
Given two union compatible document spanners $P_{1}$ and $P_{2}$,
their union is the spanner denoted as $P_{1}\cup P_{2}$, for which
we have that:
\begin{itemize}
\item $\textrm{SVars}\left(P_{1}\cup P_{2}\right)=\textrm{SVars}\left(P_{1}\right)$;
\item given a string $\mathbf{s}$, $\left(P_{1}\cup P_{2}\right)\left(\mathbf{s}\right)=P_{1}\left(\mathbf{s}\right)\cup P_{2}\left(\mathbf{s}\right)$.
\end{itemize}
\end{definition}


\subsubsection{Projection}
\begin{definition}
Given a document spanner $P$ and a set of span variables $Y\subseteq\textrm{SVars}\left(P\right)$,
the projection of $P$ over $Y$ is the spanner denoted as $\pi_{Y}P$,
satisfying $\textrm{SVars}\left(\pi_{Y}P\right)=Y$.
\end{definition}

\noindent As the name and the definition suggest, the projection of
a document spanner $P$ over a subset of its span variables $Y$ is
obtained by reducing the domain of each of the spanner's output $s-\textrm{tuples}$
to $Y$.


\subsubsection{Natural Join}
\begin{definition}
Given two document spanners $P_{1}$ and $P_{2}$, their natural join
is the spanner denoted as $P_{1}\bowtie P_{2}$, for which we have
that:
\begin{itemize}
\item $\textrm{SVars}\left(P_{1}\bowtie P_{2}\right)=\textrm{SVars}\left(P_{1}\right)\cup\textrm{SVars}\left(P_{2}\right)$;
\item given a string $\mathbf{s}$, $\left(P_{1}\bowtie P_{2}\right)\left(\mathbf{s}\right)$
consists of all the $\mathbf{s}-\textrm{tuples}$ $\mu$ agreeing
with some $\mu_{1}\in P_{1}\left(\mathbf{s}\right)$ and some $\mu_{2}\in P_{2}\left(\mathbf{s}\right)$.
Note that this implies that $\mu_{1},\mu_{2}$ agree on variables
that are common to $P_{1},P_{2}$: $\forall x\in\textrm{SVars}\left(P_{1}\right)\cap\textrm{SVars}\left(P_{2}\right)$,
$\mu_{1}\left(x\right)=\mu_{2}\left(x\right)$. 
\end{itemize}
\end{definition}


\subsubsection{String Selection}
\begin{definition}
Given a document spanner $P$ and a k-ary string relation $R$, the
string selection operation according to $R$ is denoted as $\varsigma^{R}$,
and is parametrized by $x_{1},...,x_{k}\in\textrm{SVars}\left(P\right)$.
We have that, given a string $\mathbf{s}$ and a spanner $P':=\varsigma_{x_{1},...,x_{k}}^{R}P$,
$P'\left(\mathbf{s}\right)$ consists of all the $\mathbf{s}-\textrm{tuples}$
$\mu$ such that $\left(\mathbf{s}_{\mu\left(x_{1}\right)},...,\mathbf{s}_{\mu\left(x_{k}\right)}\right)\in R$.
\end{definition}

\noindent In the remainder of this document, the only string selection
operator I consider is $\varsigma_{x,y}^{=}$ which, given a spanner
$P$, restricts $P\left(\mathbf{s}\right)$ to those $\mathbf{s}-\textrm{tuples}$
that satisfy $\mathbf{s}_{\mu\left(x\right)}=\mathbf{s}_{\mu\left(y\right)}$.

\medskip{}


\noindent I now introduce some additional notation. Given a generic
class of spanner representations $\textrm{SR}$, the set of all the
spannners that can be represented by $\textrm{SR}$ is denoted as
$\left\llbracket \textrm{SR}\right\rrbracket $. Formally, we have
that $\left\llbracket \textrm{SR}\right\rrbracket =\left\{ \left\llbracket r\right\rrbracket \mid\in\textrm{SR}\right\} $.
Let $O$ be a spanner algebra. I denote by $\textrm{SR}^{O}$ the
closure of $\textrm{SR}$ under $O$, that is: the class of spanner
represantations obtained by applying (compositions of) operators contained
in $O$ to the represantations in $\textrm{SR}$. The corresponding
set of spanners is referred to as $\left\llbracket \textrm{SR}^{O}\right\rrbracket $.
We are ready to start reasoning on the expressive power of the spanner
representations that we defined.
\begin{proposition}
The following hold:
\begin{enumerate}
\item every document spanner represented in the classes $\textrm{RGX}$
and $\textrm{VA}_{\textrm{stk}}$ is hierarchical, that is: $\left\llbracket \textrm{\textrm{RGX}}\right\rrbracket ,\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}\right\rrbracket \subseteq\mathbf{HS}$;
\item there exist some spanners represented in $\textrm{VA}_{\textrm{set}}$
that are not hierarchical: $\left\llbracket \textrm{\ensuremath{\textrm{VA}_{set}}}\right\rrbracket \nsubseteq\mathbf{HS}$;
\item the operators $\cup$, $\pi$, $\varsigma^{R}$ preserve the property
of being hierarchical, while $\bowtie$ does not, thus we have that:

\begin{enumerate}
\item given a class of spanner representations $\textrm{SR}$, $\left\llbracket \textrm{SR}\right\rrbracket \subseteq\mathbf{HS}\Rightarrow\left\llbracket \textrm{SR}^{\left\{ \cup,\pi,\varsigma^{R}\right\} }\right\rrbracket \subseteq\mathbf{HS};$
\item there exist two hierarchical spanners $P_{1},P_{2}$ such that $P_{1}\bowtie P_{2}\notin\mathbf{HS}$.
\end{enumerate}
\end{enumerate}
\end{proposition}

\noindent In the next Subsection, I discuss the class of \emph{regular
spanners}, which plays a central role in the discussion of the class
of spanners that constitute the core of AQL.


\subsection{Regular Spanners}

A regular spanner is defined as follows.
\begin{definition}
A spanner is regular if it can be defined by a vset-automaton.
\end{definition}

\noindent Let us now see how regular spanners are related to the other
basic spanner classes. A preliminary result is that regex formulas
and vstk-automata have the same expressive power.
\begin{theorem}
\label{.rgx=00003Dvstk}$\left\llbracket \textrm{\textrm{RGX}}\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}\right\rrbracket $.
\end{theorem}

\noindent It turns out that the spanners expressed by representations
in $\textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}$($\textrm{\textrm{RGX}}$)
are exactly those that are both regular and hierarchical.
\begin{theorem}
$\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}\right\rrbracket \cap\mathbf{HS}$.
\end{theorem}

\noindent For what concerns the algebraic operators I presented in
Subsection \ref{sub:Algebras-of-Spanners}, it can be shown that union,
projection and join don't increase the expressive power of regular
spanners.
\begin{theorem}
\label{.setext=00003Dset}$\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}^{\left\{ \cup,\pi,\bowtie\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}\right\rrbracket $.
\end{theorem}

\noindent On the other hand, the same operators make the spanners
represented in $\textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}$
equivalent to regular spanners.
\begin{theorem}
\label{.stkext=00003Dset}$\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}^{\left\{ \cup,\pi,\bowtie\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}\right\rrbracket $.
\end{theorem}

\noindent Finally, I look at which string relations can be simulated
by regular spanners. Let us start by defining the concept of \emph{selectable
string relation}.
\begin{definition}
Given a string relation $R$ and a class of spanners $C$, $R$ is
selectable by $C$ if for every document spanner $P\in C$ and for
every $\overrightarrow{x}=x_{1},...,x_{k}$, $x_{i}\in\textrm{SVars}\left(P\right)$,
we have that $\varsigma_{\overrightarrow{x}}^{R}P\in C$.
\end{definition}

\noindent Next, I introduce the concept of \emph{restricted universal
spanner.}
\begin{definition}
Given a string relation $R$ and a sequence of variables$\overrightarrow{x}=x_{1},...,x_{k}$
with their corrsesponding set $X=\left\{ x_{1},...,x_{k}\right\} $,
the $R-\textrm{restricted}$ universal spanner over $\overrightarrow{x}$
is $\Upsilon_{\overrightarrow{x}}^{R}:=\varsigma_{\overrightarrow{x}}^{R}\Upsilon_{X}$.
\end{definition}

\noindent Selectability of a string relation $R$ by a class of spanners
$C$ corresponds to the presence in $C$ of all the possible $R-\textrm{restricted}$
universal spanners, under some conditions.
\begin{proposition}
Given a string relation $R$ and a class of spanners $C$ containing
all the possible universal spanners and closed under natural join,
$R$ is selectable by $C$ if and only if, for every $\overrightarrow{x}=x_{1},...,x_{k}\in\textrm{SVars}^{k}$,
$\Upsilon_{\overrightarrow{x}}^{R}\in C$.
\end{proposition}

\noindent In the case of regular spanners, the class of string relations
that they can select is exactly $\textrm{REC}$.
\begin{theorem}
The class of string relations selectable by $\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}\right\rrbracket $
is $\textrm{REC}$.
\end{theorem}

\noindent The relation ``$=$'' is not in $\textrm{REC}$, thus
it is not selectable by regular spanners, nonetheless it is important
for selection predicates in AQL, which is why regular spanners are
not enough to model its core. In the following Subsection, by using
the notions and results presented so far, I describe the spanners
that are identified in REF as the core of AQL: \emph{core spanners}.


\subsection{Core Spanners}

An expression in the core of AQL belongs to $\textrm{RGX}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }$.
Consequently, a core spanner is defined as follows.
\begin{definition}
A core spanner is a document spanner belonging to $\left\llbracket \textrm{RGX}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket $.
\end{definition}

\noindent Thanks to Theorems \ref{.rgx=00003Dvstk}, \ref{.setext=00003Dset}
and \ref{.stkext=00003Dset} we can easily see that $\left\llbracket \textrm{RGX}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{stk}}}}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket $.
This shows that core spanners can be reduced to regular spanners extended
with the algebra $\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} $.
But the following lemma tells us an algebra with fewer operators is
also sufficient.
\begin{lemma}
$\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}^{\left\{ \pi,\varsigma^{=}\right\} }\right\rrbracket $.
\end{lemma}

\noindent Another lemma, known as the \emph{core simplification lemma},
gives a even more simple way of representing core spanners.
\begin{lemma}
$\mathbf{(Core\,Simplification\,Lemma)}$ Every core spanner can be
defined by an expression of the form

\begin{equation}
\pi_{V}SA
\end{equation}


\noindent where:
\begin{itemize}
\item $A$ is a vset-automaton;
\item $V\subseteq\textrm{SVars}\left(A\right)$;
\item $S$ is a sequence of string selections $\varsigma_{x,y}^{=}$, for
$x,y\in\textrm{SVars}\left(A\right)$.
\end{itemize}
\end{lemma}

\noindent Now I look at which string relations can be simulated by
core spanners. In the next definition, I define three string relations
of relevance.
\begin{definition}
Given two strings $\mathbf{s},\mathbf{t}\in\varSigma^{\ast}$:
\begin{itemize}
\item $\mathbf{s}\sqsubseteq\mathbf{t}$ if $\mathbf{s}$ is a (consecutive)
substring of t (i.e. $\mathbf{s}=\mathbf{t}_{\left[i,j\right\rangle }$);
\item $\mathbf{s}\sqsubseteq_{\textrm{prf}}\mathbf{t}$ if $\mathbf{s}$
is a prefix of t (i.e. $\mathbf{s}=\mathbf{t}_{\left[1,j\right\rangle }$);
\item $\mathbf{s}\sqsubseteq_{\textrm{sfx}}\mathbf{t}$if $\mathbf{s}$
is a suffix of t (i.e. $\mathbf{s}=\mathbf{t}_{\left[1,\left|\mathbf{t}\right|+1\right\rangle }$).
\end{itemize}
\end{definition}

\begin{proposition}
\noindent All the string relations in $\textrm{REC}$, $\mathbf{\sqsubseteq}$,
$\sqsubseteq_{\textrm{prf}}$ and $\sqsubseteq_{\textrm{sfx}}$ are
selectable by the core spanners.
\end{proposition}


\subsection{Difference}

The difference operator is defined as follows.
\begin{definition}
Given two union compatible document spanners $P_{1}$ and $P_{2}$,
their difference is the spanner $P_{1}\setminus P_{2}$, for which
we have:
\begin{itemize}
\item $\textrm{SVars}\left(P_{1}\setminus P_{2}\right)=\textrm{SVars}\left(P_{1}\right)$;
\item given a string $\mathbf{s}$, $\left(P_{1}\setminus P_{2}\right)\left(\mathbf{s}\right)=\left(P_{1}\right)\setminus\left(P_{2}\right)\left(\mathbf{s}\right)$.
\end{itemize}
\end{definition}

\noindent It can be shown that regular spanners are closed under difference.
\begin{theorem}
\label{.setdiff=00003Dset}$\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}^{\left\{ \setminus\right\} }\right\rrbracket =\left\llbracket \textrm{\ensuremath{\textrm{VA}_{\textrm{set}}}}\right\rrbracket $.
\end{theorem}

\noindent Despite the result of of Theorem \ref{.setdiff=00003Dset},
core spanners are not closed under difference, which is why this operator
has not been considered so far.
\begin{theorem}
$\left\llbracket \textrm{RGX}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=}\right\} }\right\rrbracket \subsetneq\left\llbracket \textrm{RGX}^{\left\{ \cup,\pi,\bowtie,\varsigma^{=},\setminus\right\} }\right\rrbracket $.
\end{theorem}

\include{conclusion}

\selectlanguage{english}%
\bibliographystyle{apalike}
\bibliography{xampl}


\selectlanguage{american}%
\appendix
\include{appendix}

\printindex{} 
\end{document}
