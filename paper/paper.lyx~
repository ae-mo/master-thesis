#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass ulb_thesis
\options draftfoot
\use_default_options false
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\lang english
Engineering a Runtime System for AQL
\end_layout

\begin_layout Author
your name
\end_layout

\begin_layout Degree
Docteur en XXX
\begin_inset Newline newline
\end_inset

(Département XXX, Faculté XXX)
\end_layout

\begin_layout Dedication
To my parents.
\end_layout

\begin_layout Acknowledgments
Thank you, my advisor!
\end_layout

\begin_layout Standard
\begin_inset VSpace 4cm*
\end_inset


\end_layout

\begin_layout Standard

\emph on
\begin_inset Quotes eld
\end_inset

A great citation here
\emph default

\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
\align right
X
\end_layout

\begin_layout Abstract
abstract of the thesis
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList table

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
mainmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "intro.lyx"

\end_inset


\end_layout

\begin_layout Chapter
Information Extraction
\end_layout

\begin_layout Section
Definition
\end_layout

\begin_layout Standard
Information Extraction (IE) is the discipline that addresses the task of
 extracting structured information from unstructured sources automatically.
 Sources usually take the form of text documents.
 The most explored aspect of IE is the extraction of 
\emph on
named entities.

\emph default
 Another main topic, that has become object of research only in recent years,
 is the extraction of 
\emph on
relationships
\emph default
 between entities.
 IE is a field with contributions from many different communities: Machine
 Learning, Information Retrieval, Database, Web, Document Analysis.
 The interest in towards it is motivated by the evergrowing amount of data
 that is generated by our society, that is at a point in which manual analysis
 is infeasible.
 Thus IE promises to bring value to many application domains, most notably
 the enterprise world and the Web.
 There are two main approaches to IE: 
\emph on
rule-based 
\emph default
and 
\emph on
statistical
\emph default
.
 
\end_layout

\begin_layout Section
Example Applications
\end_layout

\begin_layout Paragraph
News Tracking
\end_layout

\begin_layout Standard
The activity of tracking events in news articles.
 It can result in a lot of useful services, like automatic creation of multimedi
a news, linking articles to information pages on the entities found, etc.
\end_layout

\begin_layout Paragraph
Data Cleaning
\end_layout

\begin_layout Standard
Extracting structured forms from flat data strings (containing, e.g., addresses).
 It allows more effective decuplication of information, among the other
 things.
\end_layout

\begin_layout Paragraph
Citation Databases
\end_layout

\begin_layout Standard
Articles, conferences sites, individual research sites and similar are explored
 to obain formatted citations of publications, later stored in publicly
 accessible databases.
 They are capable to forward references and may provide aggregate statistics
 and scoring information.
 See for instance Google Scholar (
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://scholar.google.it/
\end_layout

\end_inset

).
\end_layout

\begin_layout Paragraph
Relationship Web Search
\end_layout

\begin_layout Standard
Relationship extraction would be a very useful feature to integrate into
 web search engines, as the keyword search that they offer at present time
 is only good for entity identification.
\end_layout

\begin_layout Section
Issues
\end_layout

\begin_layout Subsection
Accuracy
\end_layout

\begin_layout Standard
We measure the accuracy of an IE task with two quantities:
\end_layout

\begin_layout Itemize

\emph on
precision
\emph default
: the percentage of correctly extracted entities among the extracted entities;
\end_layout

\begin_layout Itemize

\emph on
recall
\emph default
: the percentage of entities extracted among all the existing entities in
 the input source.
\end_layout

\begin_layout Standard
The main difficulties to achieving a good level of accuracy are:
\end_layout

\begin_layout Itemize
the availability of a great set of clues that might be very different in
 nature (e.
 g.
 orghographic properties, part of speech, typical words, etc.) and that might
 be difficult to combine;
\end_layout

\begin_layout Itemize
the difficulty of finding out missed extractions;
\end_layout

\begin_layout Itemize
the fact that with the advancement of research the extracted data structures
 keep increasing in complexity (for instance it is becoming more difficult
 to identify the boundaries of an entity in a text).
\end_layout

\begin_layout Standard
While we are able to reach a very good level of accuracy for entity extraction
 (
\begin_inset Formula $90\%$
\end_inset

), relationship extraction is still quite unreliable (
\begin_inset Formula $50-70\%$
\end_inset

 accuracy), mainly due to its intrinsic complexity, superior to that of
 the task of entity extraction.
\end_layout

\begin_layout Subsection
Running Time
\end_layout

\begin_layout Standard
In its initial phase IE was interesing only to research communities.
 With the enormous amount of data they need to process, companies are now
 concerned with IE too, and 
\emph on
scalability
\emph default
 has become a central issue, while many IE systems don't address the problem
 of efficiently carrying out extraction tasks with sufficient attention.
 Efficiency is influenced most notably by the efficiency of the following
 tasks:
\end_layout

\begin_layout Itemize
filtering documents in order to actually examine only the ones that have
 good chances to contain the desired information;
\end_layout

\begin_layout Itemize
focusing on the parts of a document that contain relevant information;
\end_layout

\begin_layout Itemize
processing steps, like database querying, that are typically very expensive
 and that might have to be performed on the selected pieces of input.
\end_layout

\begin_layout Standard
Recently many solutions have been proposed to target the scalability issue;
 one of these is indeed SystemT.
\end_layout

\begin_layout Section
Entity Extraction
\begin_inset CommandInset label
LatexCommand label
name "sec:Entity-Extraction"

\end_inset


\end_layout

\begin_layout Standard
Named entities are elements of interest in a text.
 Example of entities are person names, street addresses, institutions, countries
, and so on.
 In this section and in the next one, I assume that the output of an extraction
 task is a series of labels inserted into an input text document (that becomes
 
\emph on
annotated
\emph default
), although there are other possibilities.
\end_layout

\begin_layout Subsection
Rule-based Methods
\end_layout

\begin_layout Standard
Rule-based methods employ sets of predicates that are 
\begin_inset Quotes eld
\end_inset

fired
\begin_inset Quotes erd
\end_inset

 independently.
 When a portion of input text satisfies a predicate, the predicate's associated
 action is executed.
 A predicate can be represented in the following generic form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\textrm{"Contextual Pattern}\longrightarrow\textrm{Action"}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset

Contextual patterns are a way to identify entitities by exploiting their
 properties or the context in which they are usually met.
 The most common formalism used to express them is that of 
\emph on
regular expressions
\emph default
 over tokens of the input.
 Actions mark the entities that have been identified, and might consist
 in storing them in a database or adding delimiters directly in the text.
\begin_inset Newline newline
\end_inset

Most systems in this category present a cascaded structure: an input document
 goes through a series of processing phases, and the output of a phase is
 the input of the next one.
 A famous example is that of cascading grammars: formal grammars are evaluated
 in sequence on the input.
\end_layout

\begin_layout Standard
As I said, a contextual pattern seeks for (groups of) tokens that have certain
 features.
 In the case of entity extraction, features can be classified in the following
 categories:
\end_layout

\begin_layout Itemize
string representation;
\end_layout

\begin_layout Itemize
orthography (e.g.
 small case, mixed case, number, etc.);
\end_layout

\begin_layout Itemize
part of speech;
\end_layout

\begin_layout Itemize
list of dictionaries they're contained into;
\end_layout

\begin_layout Itemize
annotation obtained in previous phases.
\end_layout

\begin_layout Standard
Rules can be hand-coded by experts or learned through learning algorithms.
 In the second case the goal is to cover each of the entities of interest
 in the training set with at least one rule.
 The obtained rules should have good recall and precision on new input.
 Moreover, when learning a set of rules, we would like to achieve a good
 level of 
\emph on
generalizability
\emph default
, that is: we would like to find the minimum set of rules accounting for
 the maximum portion of training data, with high precision.
 There are two main strategies for rule learning: 
\emph on
bottom-up
\emph default
 (start from very specific rules and make them more and more general) and
 
\emph on
top-down
\emph default
 (start with rules covering all existing instances, then specialize them).
\end_layout

\begin_layout Subsubsection
Example Rules
\end_layout

\begin_layout Standard
For the examples I use an idealized syntax, as in REF.
\end_layout

\begin_layout Example
Consider the task of identifying all mentions ISO standards in a text.
 A rule for this purpose could be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{multline}
\left(\left\{ \textrm{String}=\textrm{"ISO"}\right\} \left\{ \textrm{String}=\textrm{"/IEC"}\right\} \left\{ \textrm{?}\right\} \left\{ \textrm{String}=\textrm{"/ASTM"}\right\} \left\{ \textrm{?}\right\} \right.\\
\left.\left\{ \textrm{Orthography type}=\textrm{number}\right\} \left\{ \left\{ \textrm{String}=\textrm{":"}\right\} \left\{ \textrm{Orthography type}=\textrm{number}\right\} \right\} \left\{ \textrm{?}\right\} \right)\\
\longrightarrow\textrm{ISO Standards}
\end{multline}

\end_inset


\end_layout

\begin_layout Standard
a
\end_layout

\begin_layout Example
Multiple entities can be matched at once.
 Imagine we need to find mentions of (simple) street addresses in a text
 consisting of a street name and a street number.
 A rule that matches the name and number separatedly could be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{multline}
\left(\left\{ \textrm{Orthography type}=\textrm{mixed case word}\right\} \left\{ \textrm{*}\right\} \right)\textrm{: Name}\left(\left\{ \textrm{String}=\textrm{","}\right\} \right)\\
\left(\left\{ \textrm{Orthography type}=\textrm{number}\right\} \right)\textrm{: Number}\\
\longrightarrow\textrm{Street Name}=:\textrm{Name, }\textrm{Street Number}=:\textrm{Number}
\end{multline}

\end_inset


\end_layout

\begin_layout Subsection
Statistical Methods
\end_layout

\begin_layout Standard
Statistical methods aim to decompose the source, assigning a label to each
 element in the decomposition.
 We distinguish between three types of statistical models:
\end_layout

\begin_layout Itemize

\emph on
Token-level models
\emph default
: they assign a label to each token of the source.
 Since entities are usually comprised of multiple adjacent tokens, the tags
 used are of the forms 
\begin_inset Quotes eld
\end_inset

entity_begin
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

entity_continue
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

entity_end
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize

\emph on
Segment-level models
\emph default
: they try to find the best segmentation of the source text;
\end_layout

\begin_layout Itemize

\emph on
Grammar-based models: 
\emph default
they use formal grammars, outputting parse trees.
 All the valid parses are considered for an input document, assigning a
 score to each.
 The parse with the highest score is retained.
\end_layout

\begin_layout Standard
I now give a brief description of Token-level Models and Segment-level Models.
\end_layout

\begin_layout Subsubsection
Token-Level Models
\begin_inset CommandInset label
LatexCommand label
name "sub:Token-Level-Models"

\end_inset


\end_layout

\begin_layout Paragraph
Features
\end_layout

\begin_layout Standard
Clues are of the form 
\begin_inset Formula 
\begin{equation}
f:\left(x,y,i\right)\longmapsto\mathbb{R}
\end{equation}

\end_inset

where 
\begin_inset Formula $x$
\end_inset

 is a sequence of tokens, 
\begin_inset Formula $i$
\end_inset

 is a position in 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 is a candidate label for the token at 
\begin_inset Formula $i$
\end_inset

.
 We distinguish between these types of features:
\end_layout

\begin_layout Itemize

\emph on
word features
\emph default
;
\end_layout

\begin_layout Itemize

\emph on
orthographic features;
\end_layout

\begin_layout Itemize

\emph on
dictionary lookup features.
\end_layout

\begin_layout Paragraph
Models for Labeling Token
\end_layout

\begin_layout Standard
The best models are the ones that take into account dependencies between
 tokens, among which we may find:
\end_layout

\begin_layout Itemize

\emph on
ordered classifiers
\emph default
;
\end_layout

\begin_layout Itemize

\emph on
Hidden Markov models;
\end_layout

\begin_layout Itemize

\emph on
Maximum Entropy Taggers;
\end_layout

\begin_layout Itemize

\emph on
Conditional Markov Models;
\end_layout

\begin_layout Itemize

\emph on
Conditional Random Fields 
\emph default
(the state of the art).
\end_layout

\begin_layout Subsubsection
Segment-Level Models
\end_layout

\begin_layout Paragraph
Features
\end_layout

\begin_layout Standard
In these models the label for a segment depends on the properties of its
 token and on the previous segment.
 We can describe a segment 
\begin_inset Formula $s_{j}$
\end_inset

 as:
\begin_inset Formula 
\begin{equation}
s_{j}=\left(y_{i},l_{j},u_{j}\right)\label{eq:segment}
\end{equation}

\end_inset

where 
\begin_inset Formula $y_{i}$
\end_inset

 is the proposed label for 
\begin_inset Formula $s_{j}$
\end_inset

 and 
\begin_inset Formula $l_{j},u_{j}$
\end_inset

 are the start and end positions of 
\begin_inset Formula $s_{j}$
\end_inset

.
 Therefore, a feature is of the form:
\begin_inset Formula 
\begin{equation}
f\left(y_{i},y_{i-1},x,l_{j},u_{j}\right)
\end{equation}

\end_inset

where 
\begin_inset Formula $x$
\end_inset

 is the input sequence of tokens, 
\begin_inset Formula $y_{i-1}$
\end_inset

 is the proposed label for the previous segment and the other symbols are
 defined as for Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:segment"

\end_inset

.
 Besides token-level features (see subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Token-Level-Models"

\end_inset

), we can exploit the following feature types:
\end_layout

\begin_layout Itemize

\emph on
Similarity to an entity in a database;
\end_layout

\begin_layout Itemize

\emph on
Length of the segment.
\end_layout

\begin_layout Standard
There are also global segmentation models, that try to find the best segmentatio
n of a token sequence by maximizing a target function.
\end_layout

\begin_layout Section
Relationship Extraction
\end_layout

\begin_layout Standard
When exctracting relationship between entities, we might face three types
 of specific tasks:
\end_layout

\begin_layout Itemize
given a pair of entities, find the relationship between them;
\end_layout

\begin_layout Itemize
given an entity 
\begin_inset Formula $e$
\end_inset

 and a relationship 
\begin_inset Formula $r$
\end_inset

, find all the other entities 
\begin_inset Formula $e'$
\end_inset

 such that 
\begin_inset Formula $\left(e,e'\right)\in r$
\end_inset

;
\end_layout

\begin_layout Itemize
given a big and open-ended input and a relationship 
\begin_inset Formula $r$
\end_inset

 find all pairs of entities 
\begin_inset Formula $e',e''$
\end_inset

 such that 
\begin_inset Formula $\left(e',e''\right)\in r$
\end_inset

.
\end_layout

\begin_layout Subsection
Predicting the Relationship between a Entity Pair 
\end_layout

\begin_layout Standard
For the first task, we can exploit the following resources:
\end_layout

\begin_layout Itemize

\emph on
surface tokens
\emph default
: tokens that are usually placed between entities.
 They are strong clues;
\end_layout

\begin_layout Itemize

\emph on
part of speech tags 
\emph default
(the most important being verbs);
\end_layout

\begin_layout Itemize

\emph on
syntactic parse tree
\emph default
: allows grouping words in phrase types, e.g.
 noun phrases, propositional phrases, and so on;
\end_layout

\begin_layout Itemize

\emph on
dependency graph
\emph default
: it is a less expensive structure to compute than the parse tree and it
 links a word to those that depend on it.
\end_layout

\begin_layout Standard
The main methods available to carry out the task are:
\end_layout

\begin_layout Itemize

\emph on
Feature-based methods
\emph default
, that simply transform the clues mentioned above for usage by conventional
 classifier models;
\end_layout

\begin_layout Itemize

\emph on
Kernel-based methods
\emph default
, that use kernel functions to encode the similarity between two graphs;
\end_layout

\begin_layout Itemize

\emph on
Rule-based methods
\emph default
, creating rules over structures around pairs of entities.
\end_layout

\begin_layout Standard
The second task is a special case of the third one so I don't treat it directly.
\end_layout

\begin_layout Subsection
Finding All Possible Entity Pairs Belonging to a Relationship
\end_layout

\begin_layout Standard
The third task can be met especially when dealing with the Web.
 Usually we can exploit the following resources to fulfill it:
\end_layout

\begin_layout Itemize
the 
\emph on
types of arguments
\emph default
 of 
\begin_inset Formula $r$
\end_inset

 (that might need specific recognition patterns);
\end_layout

\begin_layout Itemize
a 
\emph on
seed database
\emph default
 of pairs of entities belonging to 
\begin_inset Formula $r$
\end_inset

;
\end_layout

\begin_layout Itemize

\emph on
manually coded patterns
\emph default
.
\end_layout

\begin_layout Standard
The generic procedure that is used in this case can be described with these
 steps:
\end_layout

\begin_layout Enumerate
Use the seed database to learn the relevant extraction patterns;
\end_layout

\begin_layout Enumerate
Use the obtained patterns to define candidate triples of the form 
\begin_inset Formula $\left(e',e'',r\right)$
\end_inset

;
\end_layout

\begin_layout Enumerate
Retain a subset of the candidate triples, using a statistical test.
\end_layout

\begin_layout Standard
There exist also rule-based methods for the task.
 
\end_layout

\begin_layout Chapter
SystemT and AQL
\end_layout

\begin_layout Standard
In this chapter, I give a description of 
\emph on
SystemT
\emph default
 and its extraction rule language 
\emph on
AQL
\emph default
 (Annotation Query Language), and of a new way of evaluating AQL queries,
 that uses a formalism derived from 
\emph on
Finite State Automata
\emph default
.
 Producing and analysing a concrete runtime system for AQL queries that
 employs this new method is the object of my thesis.
 Since SystemT is a rule-based system, I now focus only on this category.
\end_layout

\begin_layout Section
SystemT
\end_layout

\begin_layout Standard
As I mentioned in the previous chapter, scalability has now become a central
 issue to IE.
 Companies now rely on IE for many tasks; a prominent example is 
\emph on
Business Intelligence
\emph default
.
 Unfortunately, many systems developed in the past don't address this concern
 correctly.
 Traditionally, most rule-based system rely on cascading grammars: formal
 grammars are executed in sequence on the input, each grammar representing
 a stage that takes as input the ouput of the previous one.
 Rules in such grammars are matched using regular expressions: if a part
 of the input text satisfies the regular expression associated with a rule,
 that rule is activated (i.e.
 
\begin_inset Quotes eld
\end_inset

fires
\begin_inset Quotes erd
\end_inset

) and the corresponding action is executed.
 Evaluating a grammar on a document tends to be costly, because simply evaluatin
g a single rule might require scanning the whole document.
 On large datasets, the running time becomes enormous.
 What's more, these kind of systems are not able to fulfill the expressivity
 requirements of the complex extraction tasks.
\begin_inset Newline newline
\end_inset

SystemT was developed at IBM to address these issues.
 This system is based on a new approach to extraction rules: the 
\emph on
algebraic approach
\emph default
.
 Here, data manipulations are viewed as operations in a (relational) algebra.
 Extraction tasks are defined using 
\emph on
annotators
\emph default
 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Entity-Extraction"

\end_inset

) whose rules are viewed as 
\emph on
queries
\emph default
 on input documents, that act as virtual databases.
 Complex annotators are obtained by combining simple ones by means of 
\emph on
relational operators
\emph default
.
 By doing so, all the optimization techniques used in regular databases
 become available, but new techniques are possible too, due to the characteristi
cs of text documents.
 Another advantage of SystemT is that it is capable to handle 
\emph on
overlapping rule matchings
\emph default
, due to rulels being fired independently, which are difficult to resolve
 in cascading grammars, where they tipically require disambiguation policies
 that only partially solve the problem.
\begin_inset Newline newline
\end_inset

I now give an overview of SystemT's high-level structure.
 Then, I talk about its data model, execution model and algebra.
\end_layout

\begin_layout Subsection
Architecture
\end_layout

\begin_layout Standard
These are the main components of SystemT:
\end_layout

\begin_layout Description
Development
\begin_inset space ~
\end_inset

Environment: allows constructing annotators for extraction tasks.
 Rules are expressed in AQL, and compiled into an algebra.
 It supports an iterative development process.
\end_layout

\begin_layout Description
Optimizer: seeks for the best query plan for an extraction task, evaluating
 the most convenient optimization techniques in a cost-based manner.
\end_layout

\begin_layout Description
Runtime
\begin_inset space ~
\end_inset

Environment: given a query plan, it instantiates the physical operators
 corresponding to the logical ones in the plan, then it proceeds evaluating
 it on input documents.
\end_layout

\begin_layout Standard
Once the development of an annotator is complete, it is 
\emph on
published
\emph default
 to the optimizer and runtime.
 After optimization, the runtime evaluates it on a continuous stream of
 documents.
\end_layout

\begin_layout Subsection
Data Model
\end_layout

\begin_layout Standard
SystemT uses an 
\emph on
object-relational
\emph default
 data model for annotations on a text document, that allows applying logical
 operators over it, that can be composed.
 There is an important assumption to mention before continuing: an extraction
 task over a set of documents is performed one document at a time.
 This means that any relationships between entities in different documents
 are disregarded.
 This assumption is crucial to some optimization techniques that SystemT
 uses.
 While there exist tasks where considering these relationships would be
 useful (think of the Web), still a large number of relevant tasks can be
 carried out this way.
 In the following, I define the basic data types of SystemT's data model.
 
\begin_inset Newline newline
\end_inset

I consider a finite alphabet 
\begin_inset Formula $\varSigma$
\end_inset

 of symbols (characters).
 
\begin_inset Formula $\sum^{*}$
\end_inset

 denotes the set of all strings of finite length over 
\begin_inset Formula $\sum^{*}$
\end_inset

.
 A document is modeled as one such string.
 
\end_layout

\begin_layout Definition
A document is a string 
\begin_inset Formula $s\in\sum^{*}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
The most basic data type is the 
\emph on
span
\emph default
.
\end_layout

\begin_layout Definition
Given a string 
\begin_inset Formula $s=\sigma_{1}...\sigma_{n}$
\end_inset

 where 
\begin_inset Formula $\forall i$
\end_inset

, 
\begin_inset Formula $\sigma_{i}\in\Sigma$
\end_inset

, with length
\begin_inset Formula $\left|s\right|=n$
\end_inset

 and whose characters are indexed in the natural way, a span is a substring
 
\begin_inset Formula $\left[i,j\right\rangle $
\end_inset

 , where 
\begin_inset Formula $i,j$
\end_inset

 are indices of 
\begin_inset Formula $s$
\end_inset

 satisfying 
\begin_inset Formula $1\leq i\leq j\leq n+1$
\end_inset

.
 A span of 
\begin_inset Formula $s$
\end_inset

 is also denoted as 
\begin_inset Formula $s_{\left[i,j\right\rangle }$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
Spans can be aggregated in 
\emph on
tuples
\emph default
, which are finite sequences of spans
\emph on
.
 
\emph default
Let us denote the set of all possible spans of a string 
\begin_inset Formula $s$
\end_inset

 by 
\begin_inset Formula $\textrm{Spans}\left(s\right)$
\end_inset

 and by 
\begin_inset Formula $\textrm{SVars}$
\end_inset

 an infinite set of span variables, which can be assigned spans.
 A 
\begin_inset Formula $\left(V,s\right)-\textrm{tuple}$
\end_inset

 is defined as follows:
\end_layout

\begin_layout Definition
Given a set 
\begin_inset Formula $V\subseteq\textrm{SVars}$
\end_inset

, 
\begin_inset Formula $V$
\end_inset

 being finite, and a string 
\begin_inset Formula $s\in\sum^{*}$
\end_inset

, a 
\begin_inset Formula $\left(V,s\right)-\textrm{tuple}$
\end_inset

 is a mapping 
\begin_inset Formula $\mu:V\longmapsto\textrm{Spans}\left(s\right)$
\end_inset

.
 When 
\begin_inset Formula $V$
\end_inset

 is clear from the context, we might call 
\begin_inset Formula $\mu$
\end_inset

 simply a 
\begin_inset Formula $s-\textrm{tuple}$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
A set of tuples is called a 
\emph on
relation.
 
\emph default
Here, I focus on 
\emph on
span relations
\emph default
.
 What follows is the definition of a 
\begin_inset Formula $\left(V,s\right)-\textrm{relation}$
\end_inset

.
\end_layout

\begin_layout Definition
A 
\begin_inset Formula $\left(V,s\right)-\textrm{relation}$
\end_inset

 is a set of 
\begin_inset Formula $\left(V,s\right)-\textrm{tuples}$
\end_inset

.
 As before, we can speak of 
\begin_inset Formula $s-\textrm{relation}$
\end_inset

 when 
\begin_inset Formula $V$
\end_inset

 is clear.
\end_layout

\begin_layout Standard
\noindent
Each operator in the algebra takes one or more span relations as input and
 outputs a single span relation.
\end_layout

\begin_layout Subsection
Execution Model
\end_layout

\begin_layout Standard
A single document is conceived as a 
\emph on
local annotation database
\emph default
, to which annotators are applied in order to build 
\emph on
views
\emph default
.
 In general, a local database fits into main memory.
 Local databases are contained in a 
\emph on
global annotation database
\emph default
.
 The runtime of SystemT takes a global database and it annotates its local
 databases.
 The procedure is described by Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Annotating-all-local"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $E\longleftarrow\left\{ \textrm{algebra expression}\right\} $
\end_inset


\end_layout

\begin_layout Plain Layout
for localDB in globalDB do
\end_layout

\begin_layout Plain Layout
begin
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ \textrm{Read localDB into main memory}\right\} $
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $R\longleftarrow E\left(\textrm{localDB}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ \textrm{Add \ensuremath{R} to localDB}\right\} $
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\{ \textrm{Write modified localDB to disk}\right\} $
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:Annotating-all-local"

\end_inset

Annotating all local databases in a global database (taken from REF).
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
In this procedure, step 2 in the for loop is the most expensive.
\end_layout

\begin_layout Subsection
Algebra of Operators
\end_layout

\begin_layout Standard
The operators of SystemT's algebra can be classified in three groups:
\end_layout

\begin_layout Itemize

\emph on
relational operators;
\end_layout

\begin_layout Itemize

\emph on
span extraction operators;
\end_layout

\begin_layout Itemize

\emph on
span aggregation operators.
\end_layout

\begin_layout Standard
In addition, there exist some 
\emph on
span selection predicates
\emph default
 that are used for span selection.
\end_layout

\begin_layout Subsubsection
Relational Operators
\end_layout

\begin_layout Standard
Relational operators are the usual operators of relational algebra that
 appear in classical database query plans.
 Important examples are:
\end_layout

\begin_layout Itemize

\emph on
selection
\emph default
 (
\begin_inset Formula $\sigma$
\end_inset

);
\end_layout

\begin_layout Itemize

\emph on
projection 
\emph default
(
\begin_inset Formula $\pi$
\end_inset

);
\end_layout

\begin_layout Itemize

\emph on
Cartesian product 
\emph default
(
\begin_inset Formula $\times$
\end_inset

);
\end_layout

\begin_layout Itemize

\emph on
Union
\emph default
 (
\begin_inset Formula $\cup$
\end_inset

);
\end_layout

\begin_layout Itemize

\emph on
Intersection
\emph default
 (
\begin_inset Formula $\cap$
\end_inset

).
\end_layout

\begin_layout Subsubsection*
Span Extraction Operators
\end_layout

\begin_layout Standard
Loosely speaking, span extraction operators take a pattern and a document
 as input and output the maximal set of spans that match that pattern.
 There are two main span extraction operators:
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000

\emph on
standard
\begin_inset space ~
\end_inset

regular
\begin_inset space ~
\end_inset

expression
\begin_inset space ~
\end_inset

matcher
\begin_inset space ~
\end_inset

(
\begin_inset Formula $\varepsilon_{re}$
\end_inset

)
\emph default
: this operator takes a regular expression 
\begin_inset Formula $r$
\end_inset

 as input and it identifies all non-overlapping matchings of 
\begin_inset Formula $r$
\end_inset

 in the current document, from left to right.
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000

\emph on
dictionary
\begin_inset space ~
\end_inset

matcher
\begin_inset space ~
\end_inset

(
\begin_inset Formula $\varepsilon_{d}$
\end_inset

)
\emph default
:
\emph on
 
\emph default
this operator outputs all the spans that match some entry in a given dictionary.
\end_layout

\begin_layout Standard
Although the dictionary matcher might seem useless since there is a regular
 expression matcher, it has some advantages over it, as the fact that it
 can find overlapping matchings or that it enforces the semantics of word
 boundaries.
\end_layout

\begin_layout Subsubsection*
Span Aggregation Operators
\end_layout

\begin_layout Standard
Span aggregation operators are used to aggregate spans in a meaningful way.
 They are of two types:
\end_layout

\begin_layout Itemize

\emph on
Consolidation
\emph default
: they are used to coalesce overlapping spans that were matched using patterns
 for the same concept.
 They are: 
\end_layout

\begin_deeper
\begin_layout Labeling
\labelwidthstring 00.00.0000

\emph on
containment
\begin_inset space ~
\end_inset

consolidation
\begin_inset space ~
\end_inset

(
\begin_inset Formula $\varOmega_{c}$
\end_inset

)
\emph default
:
\emph on
 
\emph default
it discards a span if it is fully contained into another one.
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000

\emph on
overlap
\begin_inset space ~
\end_inset

consolidation
\begin_inset space ~
\end_inset

(
\begin_inset Formula $\varOmega_{o}$
\end_inset

)
\emph default
:
\emph on
 
\emph default
it merges spans that overlap repeatedly.
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
Block (
\begin_inset Formula $\beta$
\end_inset

)
\emph default
: it matches a series of spans, each at a distance from its neighbor span(s)
 that is not superior to a threshold.
 It is thought to identify regularity.
 It is tuned by two parameters: a 
\emph on
distance constraint
\emph default
 to control regularity and a 
\emph on
count constraint 
\emph default
that establishes the minimum number of spans in a block.
\end_layout

\begin_layout Subsubsection
Span Selection Predicates
\end_layout

\begin_layout Standard
Consider two spans 
\begin_inset Formula $s_{1},s_{2}$
\end_inset

.
 The main span predicates that may be used for selection are the following:
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $s_{1}\preceq_{d}s_{2}$
\end_inset

 when 
\begin_inset Formula $s_{1},s_{2}$
\end_inset

 do not overlap, 
\begin_inset Formula $s_{1}$
\end_inset

 precedes 
\begin_inset Formula $s_{2}$
\end_inset

 and there are less than 
\begin_inset Formula $d$
\end_inset

 characters between them;
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $s_{1}\simeq s_{2}$
\end_inset

 when the two spans overlap;
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $s_{1}\subset s_{2}$
\end_inset

 when 
\begin_inset Formula $s_{1}$
\end_inset

 is strictly contained in 
\begin_inset Formula $s_{2}$
\end_inset

;
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $s_{1}=s_{2}$
\end_inset

 when 
\begin_inset Formula $s_{1}$
\end_inset

 equals 
\begin_inset Formula $s_{2}$
\end_inset

.
\end_layout

\begin_layout Subsection
Optimization Techniques
\end_layout

\begin_layout Standard
As I mentioned in the introduction of this chapter, SystemT can make use
 of the optimization techniques from traditional database systems, but are
 some peculiar aspects of SystemT that enable new optimization methods.
\end_layout

\begin_layout Remark
The effect of document-at-a-time processing is that the span relations produced
 and consumed for a single document by operators are very small in size
 and often empty.
\begin_inset CommandInset label
LatexCommand label
name "small-relations"

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Remark
Evaluating an annotator on a large set of document is a 
\emph on
CPU-intensive process
\emph default
.
 This is because the running time is by far dominated by the execution of
 the operators 
\begin_inset Formula $\varepsilon_{re}$
\end_inset

 and 
\begin_inset Formula $\varepsilon_{d}$
\end_inset

.
\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Remark
Spans are nothing but 
\emph on
intervals
\emph default
, so we can exploit 
\emph on
interval algebra
\emph default
.
\begin_inset CommandInset label
LatexCommand label
name "interval-algebra"

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Standard
\noindent
With Remark 
\begin_inset CommandInset ref
LatexCommand ref
reference "small-relations"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "interval-algebra"

\end_inset

 in mind, running time can be reduced in a number of ways.
 I present them briefly.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "conclusion.lyx"

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "xampl"
options "apalike"

\end_inset


\end_layout

\begin_layout Standard
\start_of_appendix
\begin_inset CommandInset include
LatexCommand include
filename "appendix.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset index_print
LatexCommand printindex
type "idx"

\end_inset

 
\end_layout

\end_body
\end_document
